{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "id": "c1UXBZ2kzoX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7630fc-176d-41c5-a790-580da0829adf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml)\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-ml-py, pynvml\n",
            "Successfully installed nvidia-ml-py-12.560.30 pynvml-12.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iR74754xWIR3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity, tensorboard_trace_handler\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pynvml import *\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.cuda.current_device()  # 현재 GPU 디바이스 정보\n",
        "        allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # 메모리 사용량 (GB)\n",
        "        reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # 예약된 메모리 (GB)\n",
        "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
        "        print(f\"Reserved Memory: {reserved_memory:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No GPU available.\")"
      ],
      "metadata": {
        "id": "KutboPCzza4_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ],
      "metadata": {
        "id": "_8xbvf80zvjG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ntBtU40OWIR5"
      },
      "outputs": [],
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NkTBa1iCWIR5"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size, scale=(0.5, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "68SaArxkWIR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8643eb7-9463-48a2-fee7-1492d611a493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HISYmEIlWIR6"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.7\n",
        "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
        "n_valid_examples = len(trainset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(trainset, [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nKkwwymDWIR6"
      },
      "outputs": [],
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2kZE0KyvWIR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa1c82c-8566-404d-f12f-0f3a436f8eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 15000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_data), len(valid_data), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NgFbnxO2WIR7"
      },
      "outputs": [],
      "source": [
        "sample_fraction = 0.2\n",
        "\n",
        "# 무작위 인덱스 생성\n",
        "train_indices = torch.randperm(len(trainset))[:int(len(trainset) * sample_fraction)]\n",
        "valid_indices = torch.randperm(len(valid_data))[:int(len(valid_data) * sample_fraction)]\n",
        "test_indices = torch.randperm(len(testset))[:int(len(testset) * sample_fraction)]\n",
        "\n",
        "# 서브셋 생성\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "valid_subset = Subset(valid_data, valid_indices)\n",
        "test_subset = Subset(testset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-UMCcWRjWIR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a97b9b-e39e-4f2b-adda-6738d0575d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_subset), len(valid_subset), len(test_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KIuqCxeGWIR7"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "valid_iterator = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
        "test_iterator = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6mVcfuK7WIR7"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample = False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ijsu-aH8WIR7"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual = False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "                #elif isinstance(m, Bottleneck):\n",
        "                    #nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = checkpoint.checkpoint(self.layer1, x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fZ2g6Vv5WIR8"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JyqkNDbOWIR8"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock, n_blocks = [2, 2, 2, 2], channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CGaz_A9yWIR8"
      },
      "outputs": [],
      "source": [
        "model = ResNet(resnet18_config, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "Qf05XuEVY50-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579d3337-7220-4669-c91b-6b81779991a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0fCSieg3WIR8"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pretrained_model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GwVmEYKxWIR8"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디버깅용 코드 포함 버전 (LifetimeAwareMemoryPool & MelonTrainer)\n",
        "# class LifetimeAwareMemoryPool:\n",
        "#     def __init__(self, memory_budget):\n",
        "#         print(f\"[DEBUG] Initializing MemoryPool with budget: {memory_budget}\")\n",
        "#         self.memory_budget = memory_budget\n",
        "#         self.allocated_memory = 0\n",
        "#         self.memory_blocks = []\n",
        "#         self.tensor_map = {}\n",
        "\n",
        "#     def allocate(self, tensor_id, size, lifetime):\n",
        "#         print(f\"[DEBUG] Attempting to allocate tensor {tensor_id} with size {size} and lifetime {lifetime}\")\n",
        "\n",
        "#         if tensor_id in self.tensor_map:\n",
        "#             print(f\"[DEBUG] Tensor {tensor_id} already allocated\")\n",
        "#             return self.tensor_map[tensor_id]\n",
        "\n",
        "#         best_addr = self._find_best_fit(size, lifetime)\n",
        "\n",
        "#         if best_addr is None:\n",
        "#             print(f\"[DEBUG] Memory fragmented, performing compaction\")\n",
        "#             self._compact()\n",
        "#             best_addr = self._find_best_fit(size, lifetime)\n",
        "#             if best_addr is None:\n",
        "#                 print(f\"[DEBUG] Failed to allocate memory for tensor {tensor_id}\")\n",
        "#                 raise MemoryError(\"Not enough memory\")\n",
        "\n",
        "#         block_index = len(self.memory_blocks)\n",
        "#         self.memory_blocks.append((best_addr, size, tensor_id, lifetime))\n",
        "#         self.tensor_map[tensor_id] = block_index\n",
        "#         self.allocated_memory += size\n",
        "\n",
        "#         print(f\"[DEBUG] Successfully allocated tensor {tensor_id} at address {best_addr}\")\n",
        "#         return best_addr\n",
        "\n",
        "#     def free(self, tensor_id):\n",
        "#         print(f\"[DEBUG] Attempting to free tensor {tensor_id}\")\n",
        "#         if tensor_id in self.tensor_map:\n",
        "#             block_index = self.tensor_map[tensor_id]\n",
        "#             _, size, _, _ = self.memory_blocks[block_index]\n",
        "#             self.allocated_memory -= size\n",
        "#             del self.tensor_map[tensor_id]\n",
        "#             self.memory_blocks[block_index] = None\n",
        "#             print(f\"[DEBUG] Successfully freed tensor {tensor_id}\")\n",
        "#         else:\n",
        "#             print(f\"[DEBUG] Tensor {tensor_id} not found in memory pool\")\n",
        "\n",
        "#     def _find_best_fit(self, size, lifetime):\n",
        "#         print(f\"[DEBUG] Finding best fit for size {size} with lifetime {lifetime}\")\n",
        "\n",
        "#         if self.allocated_memory + size > self.memory_budget:\n",
        "#             print(f\"[DEBUG] Not enough memory in budget\")\n",
        "#             return None\n",
        "\n",
        "#         # 1. 재사용 가능한 메모리 블록 찾기\n",
        "#         available_addr = 0\n",
        "#         for block in self.memory_blocks:\n",
        "#             if block is None:\n",
        "#                 continue\n",
        "#             block_addr, block_size, block_id, block_lifetime = block\n",
        "#             print(f\"[DEBUG] Checking block at {block_addr} with size {block_size} (tensor {block_id})\")\n",
        "\n",
        "#             # 수명이 겹치지 않는 경우 해당 공간 재사용\n",
        "#             if not self._lifetimes_overlap(lifetime, block_lifetime):\n",
        "#                 print(f\"[DEBUG] Found potential reuse block at {block_addr}\")\n",
        "#                 if available_addr == 0:  # 첫 번째로 찾은 재사용 가능한 블록 사용\n",
        "#                     print(f\"[DEBUG] Reusing memory at address {available_addr}\")\n",
        "#                     return available_addr\n",
        "#             available_addr = max(available_addr, block_addr + block_size)\n",
        "\n",
        "#         # 2. 새로운 메모리 공간 할당\n",
        "#         if self.allocated_memory + size <= self.memory_budget:\n",
        "#             print(f\"[DEBUG] Allocating at new address {available_addr}\")\n",
        "#             return available_addr\n",
        "\n",
        "#         print(f\"[DEBUG] No suitable location found\")\n",
        "#         return None\n",
        "\n",
        "#     def _calculate_address_at_position(self, pos):\n",
        "#         \"\"\"주어진 위치에 맞는 메모리 주소 계산\"\"\"\n",
        "#         if pos == 0:\n",
        "#             return 0\n",
        "#         prev_block = self.memory_blocks[pos-1]\n",
        "#         return prev_block[0] + prev_block[1]\n",
        "\n",
        "#     def _compact(self):\n",
        "#         print(f\"[DEBUG] Starting memory compaction\")\n",
        "#         valid_blocks = [b for b in self.memory_blocks if b is not None]\n",
        "#         print(f\"[DEBUG] Found {len(valid_blocks)} valid blocks\")\n",
        "\n",
        "#         valid_blocks.sort(key=lambda x: x[3])\n",
        "\n",
        "#         self.memory_blocks = []\n",
        "#         self.tensor_map.clear()\n",
        "#         self.allocated_memory = 0\n",
        "\n",
        "#         current_addr = 0\n",
        "#         for _, size, tensor_id, lifetime in valid_blocks:\n",
        "#             self.memory_blocks.append((current_addr, size, tensor_id, lifetime))\n",
        "#             self.tensor_map[tensor_id] = len(self.memory_blocks) - 1\n",
        "#             self.allocated_memory += size\n",
        "#             current_addr += size\n",
        "#             print(f\"[DEBUG] Reallocated tensor {tensor_id} to address {current_addr-size}\")\n",
        "\n",
        "#     def _lifetimes_overlap(self, lifetime1, lifetime2):\n",
        "#         print(f\"[DEBUG] Checking lifetime overlap: {lifetime1} vs {lifetime2}\")\n",
        "#         start1, end1 = lifetime1\n",
        "#         start2, end2 = lifetime2\n",
        "#         overlap = not (end1 <= start2 or end2 <= start1)\n",
        "#         print(f\"[DEBUG] Overlap result: {overlap}\")\n",
        "#         return overlap\n",
        "\n",
        "\n",
        "# class MelonTrainer:\n",
        "#     def __init__(self, model, criterion, optimizer, device, memory_budget):\n",
        "#         print(f\"[DEBUG] Initializing MelonTrainer with memory budget: {memory_budget}\")\n",
        "#         self.model = model.to(device)\n",
        "#         self.criterion = criterion\n",
        "#         self.optimizer = optimizer\n",
        "#         self.device = device\n",
        "#         self.memory_budget = memory_budget\n",
        "#         self.has_bn = self._check_has_bn()\n",
        "#         print(f\"[DEBUG] Model has BatchNorm layers: {self.has_bn}\")\n",
        "#         self.memory_pool = self._initialize_memory_pool()\n",
        "\n",
        "#     def _check_has_bn(self):\n",
        "#         print(\"[DEBUG] Checking for BatchNorm layers in model\")\n",
        "#         for module in self.model.modules():\n",
        "#             if isinstance(module, nn.BatchNorm2d):\n",
        "#                 print(\"[DEBUG] Found BatchNorm2d layer\")\n",
        "#                 return True\n",
        "#         print(\"[DEBUG] No BatchNorm layers found\")\n",
        "#         return False\n",
        "\n",
        "#     def _initialize_memory_pool(self):\n",
        "#         print(\"[DEBUG] Initializing LifetimeAwareMemoryPool\")\n",
        "#         return LifetimeAwareMemoryPool(self.memory_budget)\n",
        "\n",
        "#     def train(self, train_loader):\n",
        "#         print(\"[DEBUG] Starting training\")\n",
        "#         start_time = time.monotonic()\n",
        "#         self.model.train()\n",
        "#         running_loss = 0.0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "\n",
        "#         print(\"[DEBUG] Setting up profiler\")\n",
        "#         with profile(\n",
        "#             activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "#             profile_memory=True,\n",
        "#             record_shapes=True\n",
        "#         ) as prof:\n",
        "#             for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "#                 print(f\"[DEBUG] Processing batch {batch_idx}\")\n",
        "#                 inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "#                 # Allocate memory for inputs and labels using the memory pool\n",
        "#                 input_tensor_id = f\"input_batch_{batch_idx}\"\n",
        "#                 label_tensor_id = f\"label_batch_{batch_idx}\"\n",
        "\n",
        "#                 try:\n",
        "#                     # Allocate memory for the input and label tensors\n",
        "#                     self.memory_pool.allocate(input_tensor_id, inputs.element_size() * inputs.nelement(), (batch_idx, batch_idx + 1))\n",
        "#                     self.memory_pool.allocate(label_tensor_id, labels.element_size() * labels.nelement(), (batch_idx, batch_idx + 1))\n",
        "#                     print(f\"[DEBUG] Allocated memory for input and label tensors for batch {batch_idx}\")\n",
        "#                 except MemoryError as e:\n",
        "#                     print(f\"[ERROR] Memory allocation failed for batch {batch_idx}: {e}\")\n",
        "#                     continue\n",
        "\n",
        "#                 if self.has_bn:\n",
        "#                     # BatchNorm이 있는 경우 recomputation 사용\n",
        "#                     print(\"[DEBUG] Using recomputation strategy\")\n",
        "#                     loss, acc = self._train_step_with_recomputation(inputs, labels)\n",
        "#                 else:\n",
        "#                     # BatchNorm이 없는 경우 micro-batch 사용\n",
        "#                     print(\"[DEBUG] Using micro-batch strategy\")\n",
        "#                     loss, acc = self._train_step_with_microbatch(inputs, labels)\n",
        "\n",
        "#                 running_loss += loss\n",
        "#                 correct += acc[0]\n",
        "#                 total += acc[1]\n",
        "\n",
        "#                 # Free the allocated memory after processing the batch\n",
        "#                 self.memory_pool.free(input_tensor_id)\n",
        "#                 self.memory_pool.free(label_tensor_id)\n",
        "#                 print(f\"[DEBUG] Freed memory for input and label tensors for batch {batch_idx}\")\n",
        "\n",
        "#                 print(f\"[DEBUG] Batch {batch_idx} - Loss: {loss:.4f}, Accuracy: {acc[0]/acc[1]*100:.2f}%\")\n",
        "\n",
        "#         end_time = time.monotonic()\n",
        "#         epoch_loss = running_loss / len(train_loader)\n",
        "#         accuracy = 100 * correct / total if total > 0 else 0\n",
        "\n",
        "#         print(f\"[DEBUG] Training completed - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "#         return epoch_loss, accuracy, start_time, end_time\n",
        "\n",
        "#     def _train_step_with_recomputation(self, inputs, labels):\n",
        "#         print(\"[DEBUG] Starting recomputation training step\")\n",
        "#         self.optimizer.zero_grad()\n",
        "\n",
        "#         # Forward pass with checkpoints\n",
        "#         with torch.no_grad():\n",
        "#             intermediate_outputs = []\n",
        "#             x = inputs\n",
        "\n",
        "#             print(\"[DEBUG] Processing initial layers\")\n",
        "#             x = self.model.conv1(x)\n",
        "#             x = self.model.bn1(x)\n",
        "#             x = self.model.relu(x)\n",
        "#             x = self.model.maxpool(x)\n",
        "\n",
        "#             print(\"[DEBUG] Processing main layers\")\n",
        "#             for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "#                 print(f\"[DEBUG] Processing {layer_name}\")\n",
        "#                 layer = getattr(self.model, layer_name)\n",
        "#                 x = layer(x)\n",
        "#                 if self.has_bn:\n",
        "#                     intermediate_outputs.append(x.detach())\n",
        "#                     print(f\"[DEBUG] Saved checkpoint for {layer_name}\")\n",
        "\n",
        "#         print(\"[DEBUG] Starting forward pass\")\n",
        "#         with record_function(\"forward_pass\"):\n",
        "#             outputs = self.model(inputs)\n",
        "#             if isinstance(outputs, tuple):\n",
        "#                 outputs = outputs[0]\n",
        "\n",
        "#         print(\"[DEBUG] Computing loss\")\n",
        "#         with record_function(\"loss_computation\"):\n",
        "#             loss = self.criterion(outputs, labels)\n",
        "\n",
        "#         print(\"[DEBUG] Backward pass\")\n",
        "#         with record_function(\"backward_pass\"):\n",
        "#             loss.backward()\n",
        "\n",
        "#         print(\"[DEBUG] Optimizer step\")\n",
        "#         with record_function(\"optimizer_step\"):\n",
        "#             self.optimizer.step()\n",
        "\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         correct = (predicted == labels).sum().item()\n",
        "#         total = labels.size(0)\n",
        "\n",
        "#         print(f\"[DEBUG] Step completed - Loss: {loss.item():.4f}, Accuracy: {correct/total*100:.2f}%\")\n",
        "#         return loss.item(), (correct, total)\n",
        "\n",
        "#     def _calculate_micro_batch_size(self, input_size):\n",
        "#         print(f\"[DEBUG] Calculating micro-batch size for input shape {input_size}\")\n",
        "#         tensor_size = input_size[1] * input_size[2] * input_size[3] * 4\n",
        "#         micro_batch_size = max(1, min(input_size[0], self.memory_budget // tensor_size))\n",
        "#         print(f\"[DEBUG] Calculated micro-batch size: {micro_batch_size}\")\n",
        "#         return micro_batch_size"
      ],
      "metadata": {
        "id": "B6v4yMYSu9vu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ElRmHAmtWIR8"
      },
      "outputs": [],
      "source": [
        "class LifetimeAwareMemoryPool:\n",
        "    def __init__(self, memory_budget):\n",
        "        self.memory_budget = memory_budget\n",
        "        self.allocated_memory = 0\n",
        "        self.memory_blocks = []\n",
        "        self.tensor_map = {}\n",
        "\n",
        "    def allocate(self, tensor_id, size, lifetime):\n",
        "        if tensor_id in self.tensor_map:\n",
        "            return self.tensor_map[tensor_id]\n",
        "\n",
        "        best_addr = self._find_best_fit(size, lifetime)\n",
        "\n",
        "        if best_addr is None:\n",
        "            self._compact()\n",
        "            best_addr = self._find_best_fit(size, lifetime)\n",
        "            if best_addr is None:\n",
        "                raise MemoryError(\"Not enough memory\")\n",
        "\n",
        "        block_index = len(self.memory_blocks)\n",
        "        self.memory_blocks.append((best_addr, size, tensor_id, lifetime))\n",
        "        self.tensor_map[tensor_id] = block_index\n",
        "        self.allocated_memory += size\n",
        "\n",
        "        return best_addr\n",
        "\n",
        "    def free(self, tensor_id):\n",
        "        if tensor_id in self.tensor_map:\n",
        "            block_index = self.tensor_map[tensor_id]\n",
        "            _, size, _, _ = self.memory_blocks[block_index]\n",
        "            self.allocated_memory -= size\n",
        "            del self.tensor_map[tensor_id]\n",
        "            self.memory_blocks[block_index] = None\n",
        "\n",
        "    def _find_best_fit(self, size, lifetime):\n",
        "        if self.allocated_memory + size > self.memory_budget:\n",
        "            return None\n",
        "\n",
        "        available_addr = 0\n",
        "        for block in self.memory_blocks:\n",
        "            if block is None:\n",
        "                continue\n",
        "            block_addr, block_size, block_id, block_lifetime = block\n",
        "            if not self._lifetimes_overlap(lifetime, block_lifetime):\n",
        "                if available_addr == 0:\n",
        "                    return available_addr\n",
        "            available_addr = max(available_addr, block_addr + block_size)\n",
        "\n",
        "        if self.allocated_memory + size <= self.memory_budget:\n",
        "            return available_addr\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _calculate_address_at_position(self, pos):\n",
        "        if pos == 0:\n",
        "            return 0\n",
        "        prev_block = self.memory_blocks[pos-1]\n",
        "        return prev_block[0] + prev_block[1]\n",
        "\n",
        "    def _compact(self):\n",
        "        valid_blocks = [b for b in self.memory_blocks if b is not None]\n",
        "        valid_blocks.sort(key=lambda x: x[3])\n",
        "\n",
        "        self.memory_blocks = []\n",
        "        self.tensor_map.clear()\n",
        "        self.allocated_memory = 0\n",
        "\n",
        "        current_addr = 0\n",
        "        for _, size, tensor_id, lifetime in valid_blocks:\n",
        "            self.memory_blocks.append((current_addr, size, tensor_id, lifetime))\n",
        "            self.tensor_map[tensor_id] = len(self.memory_blocks) - 1\n",
        "            self.allocated_memory += size\n",
        "            current_addr += size\n",
        "\n",
        "    def _lifetimes_overlap(self, lifetime1, lifetime2):\n",
        "        start1, end1 = lifetime1\n",
        "        start2, end2 = lifetime2\n",
        "        return not (end1 <= start2 or end2 <= start1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MelonTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, device, memory_budget):\n",
        "        self.model = model.to(device)\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.memory_budget = memory_budget\n",
        "        self.has_bn = self._check_has_bn()\n",
        "        self.memory_pool = self._initialize_memory_pool()\n",
        "\n",
        "    def _check_has_bn(self):\n",
        "        for module in self.model.modules():\n",
        "            if isinstance(module, nn.BatchNorm2d):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _initialize_memory_pool(self):\n",
        "        return LifetimeAwareMemoryPool(self.memory_budget)\n",
        "\n",
        "    def train(self, train_loader):\n",
        "        start_time = time.monotonic()\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "            # Allocate memory for inputs and labels using the memory pool\n",
        "            input_tensor_id = f\"input_batch_{batch_idx}\"\n",
        "            label_tensor_id = f\"label_batch_{batch_idx}\"\n",
        "\n",
        "            try:\n",
        "                self.memory_pool.allocate(input_tensor_id, inputs.element_size() * inputs.nelement(), (batch_idx, batch_idx + 1))\n",
        "                self.memory_pool.allocate(label_tensor_id, labels.element_size() * labels.nelement(), (batch_idx, batch_idx + 1))\n",
        "            except MemoryError:\n",
        "                continue\n",
        "\n",
        "            if self.has_bn:\n",
        "                loss, acc = self._train_step_with_recomputation(inputs, labels)\n",
        "            else:\n",
        "                loss, acc = self._train_step_with_microbatch(inputs, labels)\n",
        "\n",
        "            running_loss += loss\n",
        "            correct += acc[0]\n",
        "            total += acc[1]\n",
        "\n",
        "            self.memory_pool.free(input_tensor_id)\n",
        "            self.memory_pool.free(label_tensor_id)\n",
        "\n",
        "        end_time = time.monotonic()\n",
        "\n",
        "\n",
        "        # 훈련 후 평균 손실과 정확도 계산\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        accuracy = 100 * correct / total if total > 0 else 0\n",
        "\n",
        "        return epoch_loss, accuracy, start_time, end_time\n",
        "\n",
        "    def _train_step_with_recomputation(self, inputs, labels):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            intermediate_outputs = []\n",
        "            x = inputs\n",
        "\n",
        "            x = self.model.conv1(x)\n",
        "            x = self.model.bn1(x)\n",
        "            x = self.model.relu(x)\n",
        "            x = self.model.maxpool(x)\n",
        "\n",
        "            for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                layer = getattr(self.model, layer_name)\n",
        "                x = layer(x)\n",
        "                if self.has_bn:\n",
        "                    intermediate_outputs.append(x.detach())\n",
        "\n",
        "        outputs = self.model(inputs)\n",
        "        if isinstance(outputs, tuple):\n",
        "            outputs = outputs[0]\n",
        "\n",
        "        loss = self.criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        for i, param in enumerate(model.parameters()):\n",
        "          if i == len(list(model.parameters())) - 1:\n",
        "            break\n",
        "          if param.grad is not None:\n",
        "            grad_values = param.grad.abs().view(-1)\n",
        "            topk_values, _ = grad_values.topk(10, largest=True)\n",
        "\n",
        "            threshold = topk_values[-1]\n",
        "\n",
        "            mask = param.grad.abs() >= threshold\n",
        "\n",
        "            updated_grad = torch.zeros_like(param.grad)\n",
        "            updated_grad[mask] = param.grad[mask]\n",
        "\n",
        "            del param.grad\n",
        "            torch.cuda.empty_cache()\n",
        "            param.grad = updated_grad.clone().detach()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        total = labels.size(0)\n",
        "\n",
        "        return loss.item(), (correct, total)\n",
        "\n",
        "    def _calculate_micro_batch_size(self, input_size):\n",
        "        tensor_size = input_size[1] * input_size[2] * input_size[3] * 4\n",
        "        micro_batch_size = max(1, min(input_size[0], self.memory_budget // tensor_size))\n",
        "        return micro_batch_size"
      ],
      "metadata": {
        "id": "x380sxZ-dT2D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XcKNWVMyWIR8"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs[0], labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    # print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1X3CMJVlWIR9"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CBXgAgVO0G4p"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "aiV3uFx69SM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35f741d-098d-4f59-f402-e25495fffe16"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated Memory: 0.04 GB\n",
            "Reserved Memory: 0.06 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "PX8BoA2oYyEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794997f8-4239-46f1-ea4a-e388fb5364c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 40026.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bsG0saouWIR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab093c73-e52b-4129-b716-a6e02bb446d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/313 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "Training: 100%|██████████| 313/313 [00:34<00:00,  8.94it/s]\n",
            "Validation:   0%|          | 0/94 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Train Time: 0m 35s\n",
            "\tTrain Loss: 2.390 | Train Acc: 10.05%\n",
            "\t Val. Loss: 2.379 |  Val. Acc: 10.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.57it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.368 | Train Acc: 10.21%\n",
            "\t Val. Loss: 2.355 |  Val. Acc: 10.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.56it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.351 | Train Acc: 10.08%\n",
            "\t Val. Loss: 2.343 |  Val. Acc: 10.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.65it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.336 | Train Acc: 10.66%\n",
            "\t Val. Loss: 2.326 |  Val. Acc: 11.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.59it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.321 | Train Acc: 11.15%\n",
            "\t Val. Loss: 2.316 |  Val. Acc: 11.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.69it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.311 | Train Acc: 11.09%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 12.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.54it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.300 | Train Acc: 11.83%\n",
            "\t Val. Loss: 2.290 |  Val. Acc: 13.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.49it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.291 | Train Acc: 12.19%\n",
            "\t Val. Loss: 2.284 |  Val. Acc: 12.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.65it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.281 | Train Acc: 13.04%\n",
            "\t Val. Loss: 2.273 |  Val. Acc: 13.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.49it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.274 | Train Acc: 14.28%\n",
            "\t Val. Loss: 2.266 |  Val. Acc: 14.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.61it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.264 | Train Acc: 14.54%\n",
            "\t Val. Loss: 2.257 |  Val. Acc: 15.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.55it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.258 | Train Acc: 15.74%\n",
            "\t Val. Loss: 2.251 |  Val. Acc: 16.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.57it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.251 | Train Acc: 16.11%\n",
            "\t Val. Loss: 2.241 |  Val. Acc: 17.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.62it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.244 | Train Acc: 16.84%\n",
            "\t Val. Loss: 2.235 |  Val. Acc: 17.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.55it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.235 | Train Acc: 16.99%\n",
            "\t Val. Loss: 2.231 |  Val. Acc: 18.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.231 | Train Acc: 17.91%\n",
            "\t Val. Loss: 2.222 |  Val. Acc: 18.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.225 | Train Acc: 18.33%\n",
            "\t Val. Loss: 2.216 |  Val. Acc: 19.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.218 | Train Acc: 18.88%\n",
            "\t Val. Loss: 2.213 |  Val. Acc: 19.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.59it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.211 | Train Acc: 19.16%\n",
            "\t Val. Loss: 2.206 |  Val. Acc: 20.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.209 | Train Acc: 19.10%\n",
            "\t Val. Loss: 2.199 |  Val. Acc: 20.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.68it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.202 | Train Acc: 19.69%\n",
            "\t Val. Loss: 2.194 |  Val. Acc: 20.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.198 | Train Acc: 20.18%\n",
            "\t Val. Loss: 2.188 |  Val. Acc: 20.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.46it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.194 | Train Acc: 19.57%\n",
            "\t Val. Loss: 2.187 |  Val. Acc: 21.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.40it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.187 | Train Acc: 20.44%\n",
            "\t Val. Loss: 2.174 |  Val. Acc: 22.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.46it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.182 | Train Acc: 20.81%\n",
            "\t Val. Loss: 2.166 |  Val. Acc: 22.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.173 | Train Acc: 21.11%\n",
            "\t Val. Loss: 2.164 |  Val. Acc: 22.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.170 | Train Acc: 21.54%\n",
            "\t Val. Loss: 2.157 |  Val. Acc: 22.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.47it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.166 | Train Acc: 20.83%\n",
            "\t Val. Loss: 2.151 |  Val. Acc: 23.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.44it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.159 | Train Acc: 20.90%\n",
            "\t Val. Loss: 2.152 |  Val. Acc: 22.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.155 | Train Acc: 21.70%\n",
            "\t Val. Loss: 2.141 |  Val. Acc: 23.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.150 | Train Acc: 21.97%\n",
            "\t Val. Loss: 2.133 |  Val. Acc: 24.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.49it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.144 | Train Acc: 22.06%\n",
            "\t Val. Loss: 2.134 |  Val. Acc: 24.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.41it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.140 | Train Acc: 22.47%\n",
            "\t Val. Loss: 2.127 |  Val. Acc: 24.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.49it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.136 | Train Acc: 21.93%\n",
            "\t Val. Loss: 2.124 |  Val. Acc: 24.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.43it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.131 | Train Acc: 22.48%\n",
            "\t Val. Loss: 2.110 |  Val. Acc: 24.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.43it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.128 | Train Acc: 22.29%\n",
            "\t Val. Loss: 2.116 |  Val. Acc: 24.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.39it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.122 | Train Acc: 23.28%\n",
            "\t Val. Loss: 2.101 |  Val. Acc: 24.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.41it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.119 | Train Acc: 22.60%\n",
            "\t Val. Loss: 2.096 |  Val. Acc: 24.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.41it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.117 | Train Acc: 22.85%\n",
            "\t Val. Loss: 2.103 |  Val. Acc: 25.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.45it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.110 | Train Acc: 23.06%\n",
            "\t Val. Loss: 2.096 |  Val. Acc: 24.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.50it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.104 | Train Acc: 23.56%\n",
            "\t Val. Loss: 2.084 |  Val. Acc: 25.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.105 | Train Acc: 23.01%\n",
            "\t Val. Loss: 2.081 |  Val. Acc: 25.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.58it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.099 | Train Acc: 23.49%\n",
            "\t Val. Loss: 2.078 |  Val. Acc: 25.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.57it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.098 | Train Acc: 23.07%\n",
            "\t Val. Loss: 2.076 |  Val. Acc: 24.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.59it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.098 | Train Acc: 23.19%\n",
            "\t Val. Loss: 2.070 |  Val. Acc: 24.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.52it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.087 | Train Acc: 24.69%\n",
            "\t Val. Loss: 2.079 |  Val. Acc: 24.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.51it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.089 | Train Acc: 23.67%\n",
            "\t Val. Loss: 2.063 |  Val. Acc: 25.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.49it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.084 | Train Acc: 23.88%\n",
            "\t Val. Loss: 2.062 |  Val. Acc: 25.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.54it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49 | Epoch Train Time: 0m 32s\n",
            "\tTrain Loss: 2.078 | Train Acc: 23.81%\n",
            "\t Val. Loss: 2.058 |  Val. Acc: 25.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.42it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.076 | Train Acc: 24.20%\n",
            "\t Val. Loss: 2.060 |  Val. Acc: 24.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.40it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.074 | Train Acc: 24.03%\n",
            "\t Val. Loss: 2.053 |  Val. Acc: 25.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.40it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.074 | Train Acc: 24.57%\n",
            "\t Val. Loss: 2.046 |  Val. Acc: 24.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.39it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.069 | Train Acc: 24.25%\n",
            "\t Val. Loss: 2.048 |  Val. Acc: 25.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.38it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.066 | Train Acc: 24.62%\n",
            "\t Val. Loss: 2.043 |  Val. Acc: 25.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.42it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.060 | Train Acc: 24.68%\n",
            "\t Val. Loss: 2.041 |  Val. Acc: 25.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.44it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.058 | Train Acc: 24.99%\n",
            "\t Val. Loss: 2.035 |  Val. Acc: 26.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.41it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.056 | Train Acc: 25.16%\n",
            "\t Val. Loss: 2.033 |  Val. Acc: 25.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.40it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.054 | Train Acc: 25.27%\n",
            "\t Val. Loss: 2.036 |  Val. Acc: 26.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.35it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.053 | Train Acc: 24.72%\n",
            "\t Val. Loss: 2.026 |  Val. Acc: 25.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.40it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.046 | Train Acc: 24.69%\n",
            "\t Val. Loss: 2.024 |  Val. Acc: 25.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.43it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.045 | Train Acc: 25.35%\n",
            "\t Val. Loss: 2.024 |  Val. Acc: 25.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.36it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.041 | Train Acc: 25.42%\n",
            "\t Val. Loss: 2.020 |  Val. Acc: 26.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.42it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.042 | Train Acc: 24.94%\n",
            "\t Val. Loss: 2.015 |  Val. Acc: 26.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.37it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.034 | Train Acc: 25.18%\n",
            "\t Val. Loss: 2.012 |  Val. Acc: 25.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.43it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.036 | Train Acc: 25.63%\n",
            "\t Val. Loss: 2.007 |  Val. Acc: 25.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.44it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.032 | Train Acc: 25.13%\n",
            "\t Val. Loss: 2.012 |  Val. Acc: 26.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.032 | Train Acc: 25.45%\n",
            "\t Val. Loss: 2.005 |  Val. Acc: 25.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.34it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.031 | Train Acc: 25.25%\n",
            "\t Val. Loss: 2.003 |  Val. Acc: 26.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.35it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.020 | Train Acc: 25.38%\n",
            "\t Val. Loss: 1.999 |  Val. Acc: 25.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.39it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.026 | Train Acc: 25.47%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 26.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.35it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.018 | Train Acc: 25.47%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 25.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.018 | Train Acc: 25.78%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 27.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.44it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.015 | Train Acc: 25.65%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 25.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.32it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.010 | Train Acc: 25.99%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 26.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.36it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.007 | Train Acc: 26.28%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 26.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.30it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.002 | Train Acc: 26.42%\n",
            "\t Val. Loss: 1.977 |  Val. Acc: 26.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.004 | Train Acc: 26.47%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 26.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 2.008 | Train Acc: 26.40%\n",
            "\t Val. Loss: 1.978 |  Val. Acc: 27.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.27it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.999 | Train Acc: 26.33%\n",
            "\t Val. Loss: 1.974 |  Val. Acc: 27.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.34it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.998 | Train Acc: 26.23%\n",
            "\t Val. Loss: 1.971 |  Val. Acc: 27.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.31it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.997 | Train Acc: 26.78%\n",
            "\t Val. Loss: 1.966 |  Val. Acc: 27.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.31it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.997 | Train Acc: 26.31%\n",
            "\t Val. Loss: 1.963 |  Val. Acc: 26.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.32it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.989 | Train Acc: 26.81%\n",
            "\t Val. Loss: 1.960 |  Val. Acc: 27.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.989 | Train Acc: 26.77%\n",
            "\t Val. Loss: 1.957 |  Val. Acc: 28.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.988 | Train Acc: 26.74%\n",
            "\t Val. Loss: 1.955 |  Val. Acc: 27.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.32it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.983 | Train Acc: 26.31%\n",
            "\t Val. Loss: 1.955 |  Val. Acc: 28.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.27it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.988 | Train Acc: 25.95%\n",
            "\t Val. Loss: 1.951 |  Val. Acc: 27.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.34it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.981 | Train Acc: 26.68%\n",
            "\t Val. Loss: 1.951 |  Val. Acc: 28.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.29it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.977 | Train Acc: 26.68%\n",
            "\t Val. Loss: 1.946 |  Val. Acc: 27.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.33it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.976 | Train Acc: 27.02%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 28.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.25it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.974 | Train Acc: 27.04%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 28.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.29it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.969 | Train Acc: 27.62%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 28.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.32it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.968 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 27.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.27it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.962 | Train Acc: 27.57%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 28.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.29it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.964 | Train Acc: 27.11%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 27.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.23it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.970 | Train Acc: 26.79%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 28.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.30it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.960 | Train Acc: 27.04%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 28.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.22it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.955 | Train Acc: 27.10%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 28.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.25it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.956 | Train Acc: 27.33%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 28.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:33<00:00,  9.26it/s]\n",
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | Epoch Train Time: 0m 33s\n",
            "\tTrain Loss: 1.947 | Train Acc: 28.14%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 28.67%\n",
            "Train finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trainer = MelonTrainer(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    memory_budget=4096 * 1024**2\n",
        ")\n",
        "\n",
        "EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "total_time = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc, start_time, end_time = trainer.train(train_iterator)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    epoch_duration = epoch_mins * 60 + epoch_secs\n",
        "    total_time += epoch_duration\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Train Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
        "\n",
        "print(\"Train finished\")\n",
        "#print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "K_RbzQQEX9J5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4abaab-ce01-4dbe-e75e-eb7a5e2ed3d3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 0.42 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "mddh-LmVYhVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1688c52-527e-4c49-8215-3bd16fd181a2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 39564.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0YfjvTjYWIR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12738081-e878-4ec9-98dc-f85b7eb1a79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18 with Melon\n",
            "Total Training Time: 54m 26s\n"
          ]
        }
      ],
      "source": [
        "print(\"ResNet18 with Melon\")\n",
        "print(f'Total Training Time: {int(total_time/60)}m {int(total_time%60)}s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "-G2lgTlpwF2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a72ead1-d0d0-445f-b11d-5c07d048c3c3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::conv2d         1.50%     213.680us        55.18%       7.878ms     393.908us       0.000us         0.00%       2.692ms     134.580us            20  \n",
            "                                      aten::convolution         1.01%     144.597us        53.68%       7.664ms     383.224us       0.000us         0.00%       2.692ms     134.580us            20  \n",
            "                                     aten::_convolution        20.27%       2.894ms        52.67%       7.520ms     375.994us       0.000us         0.00%       2.692ms     134.580us            20  \n",
            "                                aten::cudnn_convolution        27.30%       3.898ms        32.40%       4.625ms     231.275us       2.692ms        65.51%       2.692ms     134.580us            20  \n",
            "                                     CheckpointFunction         6.79%     969.718us        13.90%       1.985ms       1.985ms       0.000us         0.00%       1.080ms       1.080ms             1  \n",
            "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     656.639us        15.98%     656.639us      65.664us            10  \n",
            "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     653.147us        15.90%     653.147us      17.188us            38  \n",
            "                                       aten::batch_norm         0.55%      78.111us        28.29%       4.039ms     201.942us       0.000us         0.00%     638.496us      31.925us            20  \n",
            "                           aten::_batch_norm_impl_index         1.70%     242.611us        27.74%       3.961ms     198.036us       0.000us         0.00%     638.496us      31.925us            20  \n",
            "                                 aten::cudnn_batch_norm        19.31%       2.757ms        26.04%       3.718ms     185.906us     638.496us        15.54%     638.496us      31.925us            20  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.277ms\n",
            "Self CUDA time total: 4.109ms\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}