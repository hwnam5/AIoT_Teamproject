{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "id": "c1UXBZ2kzoX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR74754xWIR3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity, tensorboard_trace_handler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pynvml import *\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.cuda.current_device()  # 현재 GPU 디바이스 정보\n",
        "        allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # 메모리 사용량 (GB)\n",
        "        reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # 예약된 메모리 (GB)\n",
        "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
        "        print(f\"Reserved Memory: {reserved_memory:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No GPU available.\")"
      ],
      "metadata": {
        "id": "KutboPCzza4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ],
      "metadata": {
        "id": "_8xbvf80zvjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntBtU40OWIR5"
      },
      "outputs": [],
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkTBa1iCWIR5"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size, scale=(0.5, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68SaArxkWIR5"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HISYmEIlWIR6"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.7\n",
        "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
        "n_valid_examples = len(trainset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(trainset, [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKkwwymDWIR6"
      },
      "outputs": [],
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kZE0KyvWIR6"
      },
      "outputs": [],
      "source": [
        "len(train_data), len(valid_data), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgFbnxO2WIR7"
      },
      "outputs": [],
      "source": [
        "sample_fraction = 0.2\n",
        "\n",
        "# 무작위 인덱스 생성\n",
        "train_indices = torch.randperm(len(trainset))[:int(len(trainset) * sample_fraction)]\n",
        "valid_indices = torch.randperm(len(valid_data))[:int(len(valid_data) * sample_fraction)]\n",
        "test_indices = torch.randperm(len(testset))[:int(len(testset) * sample_fraction)]\n",
        "\n",
        "# 서브셋 생성\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "valid_subset = Subset(valid_data, valid_indices)\n",
        "test_subset = Subset(testset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UMCcWRjWIR7"
      },
      "outputs": [],
      "source": [
        "len(train_subset), len(valid_subset), len(test_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIuqCxeGWIR7"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "valid_iterator = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
        "test_iterator = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mVcfuK7WIR7"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample = False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ijsu-aH8WIR7"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual = False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "                #elif isinstance(m, Bottleneck):\n",
        "                    #nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ2g6Vv5WIR8"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyqkNDbOWIR8"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock, n_blocks = [2, 2, 2, 2], channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvxhhdRPWIR8"
      },
      "outputs": [],
      "source": [
        "pretrained_model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApjRni8tWIR8"
      },
      "outputs": [],
      "source": [
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGaz_A9yWIR8"
      },
      "outputs": [],
      "source": [
        "model = ResNet(resnet18_config, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "Qf05XuEVY50-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fCSieg3WIR8"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pretrained_model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwVmEYKxWIR8"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디버깅용 코드 포함 버전 (LifetimeAwareMemoryPool & MelonTrainer)\n",
        "# class LifetimeAwareMemoryPool:\n",
        "#     def __init__(self, memory_budget):\n",
        "#         print(f\"[DEBUG] Initializing MemoryPool with budget: {memory_budget}\")\n",
        "#         self.memory_budget = memory_budget\n",
        "#         self.allocated_memory = 0\n",
        "#         self.memory_blocks = []\n",
        "#         self.tensor_map = {}\n",
        "\n",
        "#     def allocate(self, tensor_id, size, lifetime):\n",
        "#         print(f\"[DEBUG] Attempting to allocate tensor {tensor_id} with size {size} and lifetime {lifetime}\")\n",
        "\n",
        "#         if tensor_id in self.tensor_map:\n",
        "#             print(f\"[DEBUG] Tensor {tensor_id} already allocated\")\n",
        "#             return self.tensor_map[tensor_id]\n",
        "\n",
        "#         best_addr = self._find_best_fit(size, lifetime)\n",
        "\n",
        "#         if best_addr is None:\n",
        "#             print(f\"[DEBUG] Memory fragmented, performing compaction\")\n",
        "#             self._compact()\n",
        "#             best_addr = self._find_best_fit(size, lifetime)\n",
        "#             if best_addr is None:\n",
        "#                 print(f\"[DEBUG] Failed to allocate memory for tensor {tensor_id}\")\n",
        "#                 raise MemoryError(\"Not enough memory\")\n",
        "\n",
        "#         block_index = len(self.memory_blocks)\n",
        "#         self.memory_blocks.append((best_addr, size, tensor_id, lifetime))\n",
        "#         self.tensor_map[tensor_id] = block_index\n",
        "#         self.allocated_memory += size\n",
        "\n",
        "#         print(f\"[DEBUG] Successfully allocated tensor {tensor_id} at address {best_addr}\")\n",
        "#         return best_addr\n",
        "\n",
        "#     def free(self, tensor_id):\n",
        "#         print(f\"[DEBUG] Attempting to free tensor {tensor_id}\")\n",
        "#         if tensor_id in self.tensor_map:\n",
        "#             block_index = self.tensor_map[tensor_id]\n",
        "#             _, size, _, _ = self.memory_blocks[block_index]\n",
        "#             self.allocated_memory -= size\n",
        "#             del self.tensor_map[tensor_id]\n",
        "#             self.memory_blocks[block_index] = None\n",
        "#             print(f\"[DEBUG] Successfully freed tensor {tensor_id}\")\n",
        "#         else:\n",
        "#             print(f\"[DEBUG] Tensor {tensor_id} not found in memory pool\")\n",
        "\n",
        "#     def _find_best_fit(self, size, lifetime):\n",
        "#         print(f\"[DEBUG] Finding best fit for size {size} with lifetime {lifetime}\")\n",
        "\n",
        "#         if self.allocated_memory + size > self.memory_budget:\n",
        "#             print(f\"[DEBUG] Not enough memory in budget\")\n",
        "#             return None\n",
        "\n",
        "#         # 1. 재사용 가능한 메모리 블록 찾기\n",
        "#         available_addr = 0\n",
        "#         for block in self.memory_blocks:\n",
        "#             if block is None:\n",
        "#                 continue\n",
        "#             block_addr, block_size, block_id, block_lifetime = block\n",
        "#             print(f\"[DEBUG] Checking block at {block_addr} with size {block_size} (tensor {block_id})\")\n",
        "\n",
        "#             # 수명이 겹치지 않는 경우 해당 공간 재사용\n",
        "#             if not self._lifetimes_overlap(lifetime, block_lifetime):\n",
        "#                 print(f\"[DEBUG] Found potential reuse block at {block_addr}\")\n",
        "#                 if available_addr == 0:  # 첫 번째로 찾은 재사용 가능한 블록 사용\n",
        "#                     print(f\"[DEBUG] Reusing memory at address {available_addr}\")\n",
        "#                     return available_addr\n",
        "#             available_addr = max(available_addr, block_addr + block_size)\n",
        "\n",
        "#         # 2. 새로운 메모리 공간 할당\n",
        "#         if self.allocated_memory + size <= self.memory_budget:\n",
        "#             print(f\"[DEBUG] Allocating at new address {available_addr}\")\n",
        "#             return available_addr\n",
        "\n",
        "#         print(f\"[DEBUG] No suitable location found\")\n",
        "#         return None\n",
        "\n",
        "#     def _calculate_address_at_position(self, pos):\n",
        "#         \"\"\"주어진 위치에 맞는 메모리 주소 계산\"\"\"\n",
        "#         if pos == 0:\n",
        "#             return 0\n",
        "#         prev_block = self.memory_blocks[pos-1]\n",
        "#         return prev_block[0] + prev_block[1]\n",
        "\n",
        "#     def _compact(self):\n",
        "#         print(f\"[DEBUG] Starting memory compaction\")\n",
        "#         valid_blocks = [b for b in self.memory_blocks if b is not None]\n",
        "#         print(f\"[DEBUG] Found {len(valid_blocks)} valid blocks\")\n",
        "\n",
        "#         valid_blocks.sort(key=lambda x: x[3])\n",
        "\n",
        "#         self.memory_blocks = []\n",
        "#         self.tensor_map.clear()\n",
        "#         self.allocated_memory = 0\n",
        "\n",
        "#         current_addr = 0\n",
        "#         for _, size, tensor_id, lifetime in valid_blocks:\n",
        "#             self.memory_blocks.append((current_addr, size, tensor_id, lifetime))\n",
        "#             self.tensor_map[tensor_id] = len(self.memory_blocks) - 1\n",
        "#             self.allocated_memory += size\n",
        "#             current_addr += size\n",
        "#             print(f\"[DEBUG] Reallocated tensor {tensor_id} to address {current_addr-size}\")\n",
        "\n",
        "#     def _lifetimes_overlap(self, lifetime1, lifetime2):\n",
        "#         print(f\"[DEBUG] Checking lifetime overlap: {lifetime1} vs {lifetime2}\")\n",
        "#         start1, end1 = lifetime1\n",
        "#         start2, end2 = lifetime2\n",
        "#         overlap = not (end1 <= start2 or end2 <= start1)\n",
        "#         print(f\"[DEBUG] Overlap result: {overlap}\")\n",
        "#         return overlap\n",
        "\n",
        "\n",
        "# class MelonTrainer:\n",
        "#     def __init__(self, model, criterion, optimizer, device, memory_budget):\n",
        "#         print(f\"[DEBUG] Initializing MelonTrainer with memory budget: {memory_budget}\")\n",
        "#         self.model = model.to(device)\n",
        "#         self.criterion = criterion\n",
        "#         self.optimizer = optimizer\n",
        "#         self.device = device\n",
        "#         self.memory_budget = memory_budget\n",
        "#         self.has_bn = self._check_has_bn()\n",
        "#         print(f\"[DEBUG] Model has BatchNorm layers: {self.has_bn}\")\n",
        "#         self.memory_pool = self._initialize_memory_pool()\n",
        "\n",
        "#     def _check_has_bn(self):\n",
        "#         print(\"[DEBUG] Checking for BatchNorm layers in model\")\n",
        "#         for module in self.model.modules():\n",
        "#             if isinstance(module, nn.BatchNorm2d):\n",
        "#                 print(\"[DEBUG] Found BatchNorm2d layer\")\n",
        "#                 return True\n",
        "#         print(\"[DEBUG] No BatchNorm layers found\")\n",
        "#         return False\n",
        "\n",
        "#     def _initialize_memory_pool(self):\n",
        "#         print(\"[DEBUG] Initializing LifetimeAwareMemoryPool\")\n",
        "#         return LifetimeAwareMemoryPool(self.memory_budget)\n",
        "\n",
        "#     def train(self, train_loader):\n",
        "#         print(\"[DEBUG] Starting training\")\n",
        "#         start_time = time.monotonic()\n",
        "#         self.model.train()\n",
        "#         running_loss = 0.0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "\n",
        "#         print(\"[DEBUG] Setting up profiler\")\n",
        "#         with profile(\n",
        "#             activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "#             profile_memory=True,\n",
        "#             record_shapes=True\n",
        "#         ) as prof:\n",
        "#             for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "#                 print(f\"[DEBUG] Processing batch {batch_idx}\")\n",
        "#                 inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "#                 # Allocate memory for inputs and labels using the memory pool\n",
        "#                 input_tensor_id = f\"input_batch_{batch_idx}\"\n",
        "#                 label_tensor_id = f\"label_batch_{batch_idx}\"\n",
        "\n",
        "#                 try:\n",
        "#                     # Allocate memory for the input and label tensors\n",
        "#                     self.memory_pool.allocate(input_tensor_id, inputs.element_size() * inputs.nelement(), (batch_idx, batch_idx + 1))\n",
        "#                     self.memory_pool.allocate(label_tensor_id, labels.element_size() * labels.nelement(), (batch_idx, batch_idx + 1))\n",
        "#                     print(f\"[DEBUG] Allocated memory for input and label tensors for batch {batch_idx}\")\n",
        "#                 except MemoryError as e:\n",
        "#                     print(f\"[ERROR] Memory allocation failed for batch {batch_idx}: {e}\")\n",
        "#                     continue\n",
        "\n",
        "#                 if self.has_bn:\n",
        "#                     # BatchNorm이 있는 경우 recomputation 사용\n",
        "#                     print(\"[DEBUG] Using recomputation strategy\")\n",
        "#                     loss, acc = self._train_step_with_recomputation(inputs, labels)\n",
        "#                 else:\n",
        "#                     # BatchNorm이 없는 경우 micro-batch 사용\n",
        "#                     print(\"[DEBUG] Using micro-batch strategy\")\n",
        "#                     loss, acc = self._train_step_with_microbatch(inputs, labels)\n",
        "\n",
        "#                 running_loss += loss\n",
        "#                 correct += acc[0]\n",
        "#                 total += acc[1]\n",
        "\n",
        "#                 # Free the allocated memory after processing the batch\n",
        "#                 self.memory_pool.free(input_tensor_id)\n",
        "#                 self.memory_pool.free(label_tensor_id)\n",
        "#                 print(f\"[DEBUG] Freed memory for input and label tensors for batch {batch_idx}\")\n",
        "\n",
        "#                 print(f\"[DEBUG] Batch {batch_idx} - Loss: {loss:.4f}, Accuracy: {acc[0]/acc[1]*100:.2f}%\")\n",
        "\n",
        "#         end_time = time.monotonic()\n",
        "#         epoch_loss = running_loss / len(train_loader)\n",
        "#         accuracy = 100 * correct / total if total > 0 else 0\n",
        "\n",
        "#         print(f\"[DEBUG] Training completed - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "#         return epoch_loss, accuracy, start_time, end_time\n",
        "\n",
        "#     def _train_step_with_recomputation(self, inputs, labels):\n",
        "#         print(\"[DEBUG] Starting recomputation training step\")\n",
        "#         self.optimizer.zero_grad()\n",
        "\n",
        "#         # Forward pass with checkpoints\n",
        "#         with torch.no_grad():\n",
        "#             intermediate_outputs = []\n",
        "#             x = inputs\n",
        "\n",
        "#             print(\"[DEBUG] Processing initial layers\")\n",
        "#             x = self.model.conv1(x)\n",
        "#             x = self.model.bn1(x)\n",
        "#             x = self.model.relu(x)\n",
        "#             x = self.model.maxpool(x)\n",
        "\n",
        "#             print(\"[DEBUG] Processing main layers\")\n",
        "#             for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "#                 print(f\"[DEBUG] Processing {layer_name}\")\n",
        "#                 layer = getattr(self.model, layer_name)\n",
        "#                 x = layer(x)\n",
        "#                 if self.has_bn:\n",
        "#                     intermediate_outputs.append(x.detach())\n",
        "#                     print(f\"[DEBUG] Saved checkpoint for {layer_name}\")\n",
        "\n",
        "#         print(\"[DEBUG] Starting forward pass\")\n",
        "#         with record_function(\"forward_pass\"):\n",
        "#             outputs = self.model(inputs)\n",
        "#             if isinstance(outputs, tuple):\n",
        "#                 outputs = outputs[0]\n",
        "\n",
        "#         print(\"[DEBUG] Computing loss\")\n",
        "#         with record_function(\"loss_computation\"):\n",
        "#             loss = self.criterion(outputs, labels)\n",
        "\n",
        "#         print(\"[DEBUG] Backward pass\")\n",
        "#         with record_function(\"backward_pass\"):\n",
        "#             loss.backward()\n",
        "\n",
        "#         print(\"[DEBUG] Optimizer step\")\n",
        "#         with record_function(\"optimizer_step\"):\n",
        "#             self.optimizer.step()\n",
        "\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         correct = (predicted == labels).sum().item()\n",
        "#         total = labels.size(0)\n",
        "\n",
        "#         print(f\"[DEBUG] Step completed - Loss: {loss.item():.4f}, Accuracy: {correct/total*100:.2f}%\")\n",
        "#         return loss.item(), (correct, total)\n",
        "\n",
        "#     def _calculate_micro_batch_size(self, input_size):\n",
        "#         print(f\"[DEBUG] Calculating micro-batch size for input shape {input_size}\")\n",
        "#         tensor_size = input_size[1] * input_size[2] * input_size[3] * 4\n",
        "#         micro_batch_size = max(1, min(input_size[0], self.memory_budget // tensor_size))\n",
        "#         print(f\"[DEBUG] Calculated micro-batch size: {micro_batch_size}\")\n",
        "#         return micro_batch_size"
      ],
      "metadata": {
        "id": "B6v4yMYSu9vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElRmHAmtWIR8"
      },
      "outputs": [],
      "source": [
        "class LifetimeAwareMemoryPool:\n",
        "    def __init__(self, memory_budget):\n",
        "        self.memory_budget = memory_budget\n",
        "        self.allocated_memory = 0\n",
        "        self.memory_blocks = []\n",
        "        self.tensor_map = {}\n",
        "\n",
        "    def allocate(self, tensor_id, size, lifetime):\n",
        "        if tensor_id in self.tensor_map:\n",
        "            return self.tensor_map[tensor_id]\n",
        "\n",
        "        best_addr = self._find_best_fit(size, lifetime)\n",
        "\n",
        "        if best_addr is None:\n",
        "            self._compact()\n",
        "            best_addr = self._find_best_fit(size, lifetime)\n",
        "            if best_addr is None:\n",
        "                raise MemoryError(\"Not enough memory\")\n",
        "\n",
        "        block_index = len(self.memory_blocks)\n",
        "        self.memory_blocks.append((best_addr, size, tensor_id, lifetime))\n",
        "        self.tensor_map[tensor_id] = block_index\n",
        "        self.allocated_memory += size\n",
        "\n",
        "        return best_addr\n",
        "\n",
        "    def free(self, tensor_id):\n",
        "        if tensor_id in self.tensor_map:\n",
        "            block_index = self.tensor_map[tensor_id]\n",
        "            _, size, _, _ = self.memory_blocks[block_index]\n",
        "            self.allocated_memory -= size\n",
        "            del self.tensor_map[tensor_id]\n",
        "            self.memory_blocks[block_index] = None\n",
        "\n",
        "    def _find_best_fit(self, size, lifetime):\n",
        "        if self.allocated_memory + size > self.memory_budget:\n",
        "            return None\n",
        "\n",
        "        available_addr = 0\n",
        "        for block in self.memory_blocks:\n",
        "            if block is None:\n",
        "                continue\n",
        "            block_addr, block_size, block_id, block_lifetime = block\n",
        "            if not self._lifetimes_overlap(lifetime, block_lifetime):\n",
        "                if available_addr == 0:\n",
        "                    return available_addr\n",
        "            available_addr = max(available_addr, block_addr + block_size)\n",
        "\n",
        "        if self.allocated_memory + size <= self.memory_budget:\n",
        "            return available_addr\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _calculate_address_at_position(self, pos):\n",
        "        if pos == 0:\n",
        "            return 0\n",
        "        prev_block = self.memory_blocks[pos-1]\n",
        "        return prev_block[0] + prev_block[1]\n",
        "\n",
        "    def _compact(self):\n",
        "        valid_blocks = [b for b in self.memory_blocks if b is not None]\n",
        "        valid_blocks.sort(key=lambda x: x[3])\n",
        "\n",
        "        self.memory_blocks = []\n",
        "        self.tensor_map.clear()\n",
        "        self.allocated_memory = 0\n",
        "\n",
        "        current_addr = 0\n",
        "        for _, size, tensor_id, lifetime in valid_blocks:\n",
        "            self.memory_blocks.append((current_addr, size, tensor_id, lifetime))\n",
        "            self.tensor_map[tensor_id] = len(self.memory_blocks) - 1\n",
        "            self.allocated_memory += size\n",
        "            current_addr += size\n",
        "\n",
        "    def _lifetimes_overlap(self, lifetime1, lifetime2):\n",
        "        start1, end1 = lifetime1\n",
        "        start2, end2 = lifetime2\n",
        "        return not (end1 <= start2 or end2 <= start1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MelonTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, device, memory_budget):\n",
        "        self.model = model.to(device)\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.memory_budget = memory_budget\n",
        "        self.has_bn = self._check_has_bn()\n",
        "        self.memory_pool = self._initialize_memory_pool()\n",
        "\n",
        "    def _check_has_bn(self):\n",
        "        for module in self.model.modules():\n",
        "            if isinstance(module, nn.BatchNorm2d):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _initialize_memory_pool(self):\n",
        "        return LifetimeAwareMemoryPool(self.memory_budget)\n",
        "\n",
        "    def train(self, train_loader):\n",
        "        start_time = time.monotonic()\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with profile(\n",
        "            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "            profile_memory=True,\n",
        "            record_shapes=True\n",
        "        ) as prof:\n",
        "            for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "                # Allocate memory for inputs and labels using the memory pool\n",
        "                input_tensor_id = f\"input_batch_{batch_idx}\"\n",
        "                label_tensor_id = f\"label_batch_{batch_idx}\"\n",
        "\n",
        "                try:\n",
        "                    self.memory_pool.allocate(input_tensor_id, inputs.element_size() * inputs.nelement(), (batch_idx, batch_idx + 1))\n",
        "                    self.memory_pool.allocate(label_tensor_id, labels.element_size() * labels.nelement(), (batch_idx, batch_idx + 1))\n",
        "                except MemoryError:\n",
        "                    continue\n",
        "\n",
        "                if self.has_bn:\n",
        "                    loss, acc = self._train_step_with_recomputation(inputs, labels)\n",
        "                else:\n",
        "                    loss, acc = self._train_step_with_microbatch(inputs, labels)\n",
        "\n",
        "                running_loss += loss\n",
        "                correct += acc[0]\n",
        "                total += acc[1]\n",
        "\n",
        "                self.memory_pool.free(input_tensor_id)\n",
        "                self.memory_pool.free(label_tensor_id)\n",
        "\n",
        "        end_time = time.monotonic()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        accuracy = 100 * correct / total if total > 0 else 0\n",
        "\n",
        "        return epoch_loss, accuracy, start_time, end_time\n",
        "\n",
        "    def _train_step_with_recomputation(self, inputs, labels):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            intermediate_outputs = []\n",
        "            x = inputs\n",
        "\n",
        "            x = self.model.conv1(x)\n",
        "            x = self.model.bn1(x)\n",
        "            x = self.model.relu(x)\n",
        "            x = self.model.maxpool(x)\n",
        "\n",
        "            for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                layer = getattr(self.model, layer_name)\n",
        "                x = layer(x)\n",
        "                if self.has_bn:\n",
        "                    intermediate_outputs.append(x.detach())\n",
        "\n",
        "        with record_function(\"forward_pass\"):\n",
        "            outputs = self.model(inputs)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]\n",
        "\n",
        "        with record_function(\"loss_computation\"):\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "        with record_function(\"backward_pass\"):\n",
        "            loss.backward()\n",
        "\n",
        "        with record_function(\"optimizer_step\"):\n",
        "            self.optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        total = labels.size(0)\n",
        "\n",
        "        return loss.item(), (correct, total)\n",
        "\n",
        "    def _calculate_micro_batch_size(self, input_size):\n",
        "        tensor_size = input_size[1] * input_size[2] * input_size[3] * 4\n",
        "        micro_batch_size = max(1, min(input_size[0], self.memory_budget // tensor_size))\n",
        "        return micro_batch_size"
      ],
      "metadata": {
        "id": "x380sxZ-dT2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcKNWVMyWIR8"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs[0], labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    # print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X3CMJVlWIR9"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CBXgAgVO0G4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "aiV3uFx69SM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "PX8BoA2oYyEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsG0saouWIR9"
      },
      "outputs": [],
      "source": [
        "trainer = MelonTrainer(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    memory_budget=4096 * 1024**2\n",
        ")\n",
        "\n",
        "EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "total_time = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.monotonic()\n",
        "    train_loss, train_acc, start_time, end_time = trainer.train(train_iterator)\n",
        "    print_gpu_utilization()\n",
        "    free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "    print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "    print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")\n",
        "    end_time = time.monotonic()\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    total_time += end_time - start_time\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Train Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
        "\n",
        "print(\"Train finished\")\n",
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "K_RbzQQEX9J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "id": "mddh-LmVYhVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YfjvTjYWIR9"
      },
      "outputs": [],
      "source": [
        "print(\"ResNet18 with Melon\")\n",
        "print(f'Total Training Time: {int(total_time/60)}m {int(total_time%60)}s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=50))"
      ],
      "metadata": {
        "id": "-G2lgTlpwF2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}