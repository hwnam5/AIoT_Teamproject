{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1UXBZ2kzoX1",
        "outputId": "88199821-2a5f-4d41-a537-4a8758976390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iR74754xWIR3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pynvml import *\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KutboPCzza4_"
      },
      "outputs": [],
      "source": [
        "def print_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.cuda.current_device()  # 현재 GPU 디바이스 정보\n",
        "        allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # 메모리 사용량 (GB)\n",
        "        reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # 예약된 메모리 (GB)\n",
        "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
        "        print(f\"Reserved Memory: {reserved_memory:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No GPU available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_8xbvf80zvjG"
      },
      "outputs": [],
      "source": [
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ntBtU40OWIR5"
      },
      "outputs": [],
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NkTBa1iCWIR5"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size, scale=(0.5, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68SaArxkWIR5",
        "outputId": "721b76dd-b106-482e-ef6f-17f406b08b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 98.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HISYmEIlWIR6"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.7\n",
        "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
        "n_valid_examples = len(trainset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(trainset, [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nKkwwymDWIR6"
      },
      "outputs": [],
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kZE0KyvWIR6",
        "outputId": "09109c9f-c2e8-477f-83cb-f37c8d0746ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 15000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_data), len(valid_data), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NgFbnxO2WIR7"
      },
      "outputs": [],
      "source": [
        "sample_fraction = 0.2\n",
        "\n",
        "# 무작위 인덱스 생성\n",
        "train_indices = torch.randperm(len(trainset))[:int(len(trainset) * sample_fraction)]\n",
        "valid_indices = torch.randperm(len(valid_data))[:int(len(valid_data) * sample_fraction)]\n",
        "test_indices = torch.randperm(len(testset))[:int(len(testset) * sample_fraction)]\n",
        "\n",
        "# 서브셋 생성\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "valid_subset = Subset(valid_data, valid_indices)\n",
        "test_subset = Subset(testset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UMCcWRjWIR7",
        "outputId": "610b1583-30af-402d-9077-61641da88f2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_subset), len(valid_subset), len(test_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KIuqCxeGWIR7"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "valid_iterator = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
        "test_iterator = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6mVcfuK7WIR7"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample = False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ijsu-aH8WIR7"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual = False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "                #elif isinstance(m, Bottleneck):\n",
        "                    #nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fZ2g6Vv5WIR8"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JyqkNDbOWIR8"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock, n_blocks = [2, 2, 2, 2], channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvxhhdRPWIR8",
        "outputId": "a6bbbfbd-5554-4c4c-a007-f93308ce2dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ],
      "source": [
        "pretrained_model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApjRni8tWIR8",
        "outputId": "fad422b9-759f-4079-ea7e-325d8ca74a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CGaz_A9yWIR8"
      },
      "outputs": [],
      "source": [
        "model = ResNet(resnet18_config, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf05XuEVY50-",
        "outputId": "a232295c-e950-470e-c4d9-7742198e9f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I-fZ50Ozf97u"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0fCSieg3WIR8"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pretrained_model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GwVmEYKxWIR8"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'key=(?P<key>\\S+)\\s+'\n",
        "                     r'self_cpu_time=(?P<self_cpu_time>\\S+)\\s+'\n",
        "                     r'cpu_time=(?P<cpu_time>\\S+)\\s+'\n",
        "                     r'self_cuda_time=(?P<self_cuda_time>\\S+)\\s+'\n",
        "                     r'cuda_time=(?P<cuda_time>\\S+)\\s+'\n",
        "                     r'input_shapes=(?P<input_shapes>\\S*)\\s*'\n",
        "                     r'cpu_memory_usage=(?P<cpu_memory_usage>\\S*)\\s*'\n",
        "                     r'cuda_memory_usage=(?P<cuda_memory_usage>\\S*)')"
      ],
      "metadata": {
        "id": "qJaIA_0BTc_t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ElRmHAmtWIR8"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    start_time = time.monotonic()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    alpha = optimizer.param_groups[0]['lr']\n",
        "    # PyTorch Profiler 시작\n",
        "    with profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "        profile_memory=True,  # 메모리 사용량 추적\n",
        "        record_shapes=True  # 텐서 크기 기록\n",
        "    ) as prof:\n",
        "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            for param in model.parameters():\n",
        "              if param.grad is not None:\n",
        "                  param.grad.zero_()\n",
        "            #optimizer.zero_grad()  # 기울기 초기화\n",
        "\n",
        "            with record_function(\"forward_pass\"):  # Forward pass 프로파일링\n",
        "                outputs = model(inputs)  # 모델 연산\n",
        "\n",
        "            with record_function(\"loss_computation\"):  # 손실 계산 프로파일링\n",
        "                loss = criterion(outputs[0], labels)  # 손실 계산\n",
        "\n",
        "            with record_function(\"backward_pass\"):  # Backward pass 프로파일링\n",
        "                loss.backward()  # 역전파\n",
        "\n",
        "            with record_function(\"optimizer_step\"):  # 파라미터 업데이트 프로파일링\n",
        "                #optimizer.step()  # 파라미터 업데이트\n",
        "                with torch.no_grad():\n",
        "                  for param in model.parameters():\n",
        "                    if param.grad is not None:\n",
        "                      param -= alpha * param.grad\n",
        "\n",
        "            # 손실 및 정확도 누적\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    # 프로파일링 결과 요약 출력\n",
        "    selected_keys = [\"forward_pass\", \"loss_computation\", \"backward_pass\", \"optimizer_step\"]\n",
        "\n",
        "    # key_averages()로부터 얻은 평균값을 필터링\n",
        "    filtered_averages = [avg for avg in prof.key_averages() if avg.key in selected_keys]\n",
        "    extracted_data = []\n",
        "\n",
        "    for avg in filtered_averages:\n",
        "      avg_str = str(avg)\n",
        "      match = pattern.search(avg_str)\n",
        "      if match:\n",
        "        extracted_data.append(match.groupdict())\n",
        "    df = pd.DataFrame(extracted_data)\n",
        "    print(df)\n",
        "    #print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    # 훈련 후 평균 손실과 정확도 계산\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, accuracy, start_time, end_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XcKNWVMyWIR8"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs[0], labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    # print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CBXgAgVO0G4p"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_BteniXzv1",
        "outputId": "7bb91656-9c1c-47c6-be8a-338e936c35ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 40026.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ],
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsG0saouWIR9",
        "outputId": "d038c42b-d48b-4180-b6d4-15cd1edd541d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:31<00:00,  9.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     750.928ms   12.275ms        0.000us    4.904ms   \n",
            "1      forward_pass       0.000us    0.000us         3.151s   10.035ms   \n",
            "2  loss_computation      33.948ms  510.254us        0.000us    6.037us   \n",
            "3  loss_computation       0.000us    0.000us       49.623ms  158.540us   \n",
            "4     backward_pass        4.141s   13.330ms        0.000us    1.746us   \n",
            "5     backward_pass       0.000us    0.000us      546.624us    1.746us   \n",
            "6    optimizer_step     404.464ms    3.497ms        0.000us  410.664us   \n",
            "7    optimizer_step       0.000us    0.000us      235.144ms  751.258us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216906802176>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216844656640>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Train Time: 1m 3s\n",
            "\tTrain Loss: 2.034 | Train Acc: 25.75%\n",
            "\t Val. Loss: 1.821 |  Val. Acc: 34.43%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:27<00:00, 11.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     709.980ms    8.446ms        0.000us    4.903ms   \n",
            "1      forward_pass       0.000us    0.000us         2.553s    8.156ms   \n",
            "2  loss_computation      30.110ms  208.811us        0.000us    6.033us   \n",
            "3  loss_computation       0.000us    0.000us       18.584ms   59.374us   \n",
            "4     backward_pass        3.434s   11.021ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.196us    1.748us   \n",
            "6    optimizer_step     383.679ms    3.218ms        0.000us  410.392us   \n",
            "7    optimizer_step       0.000us    0.000us      188.392ms  601.892us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216907260928>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901444608>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:05<00:00, 17.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Epoch Train Time: 0m 58s\n",
            "\tTrain Loss: 1.792 | Train Acc: 34.69%\n",
            "\t Val. Loss: 1.669 |  Val. Acc: 37.83%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     699.834ms    8.333ms        0.000us    4.905ms   \n",
            "1      forward_pass       0.000us    0.000us         2.524s    8.065ms   \n",
            "2  loss_computation      28.353ms  202.612us        0.000us    6.030us   \n",
            "3  loss_computation       0.000us    0.000us       18.505ms   59.120us   \n",
            "4     backward_pass        3.386s   10.866ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      546.973us    1.748us   \n",
            "6    optimizer_step     380.321ms    3.202ms        0.000us  410.512us   \n",
            "7    optimizer_step       0.000us    0.000us      188.115ms  601.008us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216913683456>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901444608>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:05<00:00, 15.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Epoch Train Time: 0m 57s\n",
            "\tTrain Loss: 1.688 | Train Acc: 38.33%\n",
            "\t Val. Loss: 1.576 |  Val. Acc: 42.43%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:30<00:00, 10.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     724.603ms    8.661ms        0.000us    4.905ms   \n",
            "1      forward_pass       0.000us    0.000us         2.625s    8.387ms   \n",
            "2  loss_computation      28.203ms  204.088us        0.000us    6.036us   \n",
            "3  loss_computation       0.000us    0.000us       18.926ms   60.466us   \n",
            "4     backward_pass        3.378s   10.841ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.082us    1.748us   \n",
            "6    optimizer_step     406.157ms    3.341ms        0.000us  410.527us   \n",
            "7    optimizer_step       0.000us    0.000us      191.153ms  610.712us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216913683456>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:05<00:00, 15.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Epoch Train Time: 1m 1s\n",
            "\tTrain Loss: 1.626 | Train Acc: 40.77%\n",
            "\t Val. Loss: 1.550 |  Val. Acc: 43.03%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:28<00:00, 11.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     710.250ms    8.440ms        0.000us    4.906ms   \n",
            "1      forward_pass       0.000us    0.000us         2.558s    8.174ms   \n",
            "2  loss_computation      28.711ms  204.478us        0.000us    6.035us   \n",
            "3  loss_computation       0.000us    0.000us       18.645ms   59.568us   \n",
            "4     backward_pass        3.397s   10.900ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.105us    1.748us   \n",
            "6    optimizer_step     388.009ms    3.254ms        0.000us  410.496us   \n",
            "7    optimizer_step       0.000us    0.000us      188.667ms  602.770us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 15.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Epoch Train Time: 0m 59s\n",
            "\tTrain Loss: 1.559 | Train Acc: 43.25%\n",
            "\t Val. Loss: 1.485 |  Val. Acc: 46.77%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:31<00:00,  9.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     718.199ms    8.623ms        0.000us    4.906ms   \n",
            "1      forward_pass       0.000us    0.000us         2.614s    8.352ms   \n",
            "2  loss_computation      29.401ms  208.578us        0.000us    6.032us   \n",
            "3  loss_computation       0.000us    0.000us       18.996ms   60.689us   \n",
            "4     backward_pass        3.417s   10.964ms        0.000us    1.749us   \n",
            "5     backward_pass       0.000us    0.000us      547.550us    1.749us   \n",
            "6    optimizer_step     402.628ms    3.312ms        0.000us  410.461us   \n",
            "7    optimizer_step       0.000us    0.000us      192.451ms  614.859us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 14.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Epoch Train Time: 1m 3s\n",
            "\tTrain Loss: 1.512 | Train Acc: 45.33%\n",
            "\t Val. Loss: 1.436 |  Val. Acc: 47.63%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:30<00:00, 10.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     716.480ms    8.546ms        0.000us    4.905ms   \n",
            "1      forward_pass       0.000us    0.000us         2.590s    8.274ms   \n",
            "2  loss_computation      28.388ms  203.161us        0.000us    6.035us   \n",
            "3  loss_computation       0.000us    0.000us       18.540ms   59.234us   \n",
            "4     backward_pass        3.437s   11.029ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.233us    1.748us   \n",
            "6    optimizer_step     393.096ms    3.259ms        0.000us  410.468us   \n",
            "7    optimizer_step       0.000us    0.000us      192.916ms  616.347us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 15.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Epoch Train Time: 1m 2s\n",
            "\tTrain Loss: 1.474 | Train Acc: 46.80%\n",
            "\t Val. Loss: 1.439 |  Val. Acc: 47.63%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:31<00:00,  9.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     716.130ms    8.600ms        0.000us    4.905ms   \n",
            "1      forward_pass       0.000us    0.000us         2.605s    8.323ms   \n",
            "2  loss_computation      28.928ms  206.737us        0.000us    6.030us   \n",
            "3  loss_computation       0.000us    0.000us       18.788ms   60.026us   \n",
            "4     backward_pass        3.411s   10.947ms        0.000us    1.750us   \n",
            "5     backward_pass       0.000us    0.000us      547.603us    1.750us   \n",
            "6    optimizer_step     399.751ms    3.278ms        0.000us  410.483us   \n",
            "7    optimizer_step       0.000us    0.000us      191.283ms  611.127us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 14.69it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Epoch Train Time: 1m 3s\n",
            "\tTrain Loss: 1.430 | Train Acc: 48.23%\n",
            "\t Val. Loss: 1.331 |  Val. Acc: 52.13%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:30<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     712.177ms    8.533ms        0.000us    4.904ms   \n",
            "1      forward_pass       0.000us    0.000us         2.578s    8.235ms   \n",
            "2  loss_computation      29.565ms  209.331us        0.000us    6.036us   \n",
            "3  loss_computation       0.000us    0.000us       18.937ms   60.502us   \n",
            "4     backward_pass        3.445s   11.056ms        0.000us    1.746us   \n",
            "5     backward_pass       0.000us    0.000us      546.495us    1.746us   \n",
            "6    optimizer_step     398.206ms    3.274ms        0.000us  410.443us   \n",
            "7    optimizer_step       0.000us    0.000us      190.823ms  609.657us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 13.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09 | Epoch Train Time: 1m 1s\n",
            "\tTrain Loss: 1.397 | Train Acc: 49.60%\n",
            "\t Val. Loss: 1.387 |  Val. Acc: 49.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:32<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     724.639ms    8.737ms        0.000us    4.906ms   \n",
            "1      forward_pass       0.000us    0.000us         2.645s    8.452ms   \n",
            "2  loss_computation      29.882ms  211.188us        0.000us    6.033us   \n",
            "3  loss_computation       0.000us    0.000us       19.047ms   60.854us   \n",
            "4     backward_pass        3.428s   10.999ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.174us    1.748us   \n",
            "6    optimizer_step     413.056ms    3.354ms        0.000us  410.452us   \n",
            "7    optimizer_step       0.000us    0.000us      194.777ms  622.291us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:06<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | Epoch Train Time: 1m 6s\n",
            "\tTrain Loss: 1.365 | Train Acc: 50.21%\n",
            "\t Val. Loss: 1.332 |  Val. Acc: 51.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:30<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                key self_cpu_time   cpu_time self_cuda_time  cuda_time  \\\n",
            "0      forward_pass     705.170ms    8.522ms        0.000us    4.906ms   \n",
            "1      forward_pass       0.000us    0.000us         2.581s    8.245ms   \n",
            "2  loss_computation      28.918ms  204.796us        0.000us    6.036us   \n",
            "3  loss_computation       0.000us    0.000us       18.529ms   59.197us   \n",
            "4     backward_pass        3.413s   10.953ms        0.000us    1.748us   \n",
            "5     backward_pass       0.000us    0.000us      547.100us    1.748us   \n",
            "6    optimizer_step     397.199ms    3.274ms        0.000us  410.490us   \n",
            "7    optimizer_step       0.000us    0.000us      193.002ms  616.620us   \n",
            "\n",
            "  input_shapes cpu_memory_usage cuda_memory_usage  \n",
            "0                             0     216900838400>  \n",
            "1                             0                0>  \n",
            "2                             0           641024>  \n",
            "3                             0                0>  \n",
            "4                             0    -216901445120>  \n",
            "5                             0                0>  \n",
            "6                             0                0>  \n",
            "7                             0                0>  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:07<00:00, 13.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 | Epoch Train Time: 1m 2s\n",
            "\tTrain Loss: 1.336 | Train Acc: 52.30%\n",
            "\t Val. Loss: 1.272 |  Val. Acc: 53.30%\n",
            "Train finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "total_time = 0\n",
        "for epoch in range(EPOCHS + 1):\n",
        "\n",
        "    train_loss, train_acc, start_time, end_time = train(model, train_iterator, criterion, optimizer, device)\n",
        "\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    #if valid_loss < best_valid_loss:\n",
        "        #best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'vgg19-model.pt')\n",
        "\n",
        "    # end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    total_time += end_time - start_time\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Train Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
        "\n",
        "print(\"Train finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mddh-LmVYhVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8726a467-835c-4c27-c750-ec17f66afa4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 38544.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ],
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0YfjvTjYWIR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6027bd8a-0de5-4456-acb5-00eba2bbcc81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18\n",
            "Total Training Time: 11m 20s\n"
          ]
        }
      ],
      "source": [
        "print(\"ResNet18\")\n",
        "print(f'Total Training Time: {int(total_time/60)}m {int(total_time%60)}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GG41xbRBaqEt"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pPqa67aoatE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8c0d8f-6d47-4959-f8c7-e3bddc9db8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model file size: 42.73 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "model_file_size = os.path.getsize('trained_model.pth')  # 바이트 단위\n",
        "model_file_size_MB = model_file_size / (1024 ** 2)  # MB로 변환\n",
        "print(f\"Saved model file size: {model_file_size_MB:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GcaaiNYha3pK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a109380e-075b-4d7b-c026-9c67c7910619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight - Size: torch.Size([64, 3, 7, 7]) - Number of elements: 9408\n",
            "bn1.weight - Size: torch.Size([64]) - Number of elements: 64\n",
            "bn1.bias - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.0.conv1.weight - Size: torch.Size([64, 64, 3, 3]) - Number of elements: 36864\n",
            "layer1.0.bn1.weight - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.0.bn1.bias - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.0.conv2.weight - Size: torch.Size([64, 64, 3, 3]) - Number of elements: 36864\n",
            "layer1.0.bn2.weight - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.0.bn2.bias - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.1.conv1.weight - Size: torch.Size([64, 64, 3, 3]) - Number of elements: 36864\n",
            "layer1.1.bn1.weight - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.1.bn1.bias - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.1.conv2.weight - Size: torch.Size([64, 64, 3, 3]) - Number of elements: 36864\n",
            "layer1.1.bn2.weight - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer1.1.bn2.bias - Size: torch.Size([64]) - Number of elements: 64\n",
            "layer2.0.conv1.weight - Size: torch.Size([128, 64, 3, 3]) - Number of elements: 73728\n",
            "layer2.0.bn1.weight - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.0.bn1.bias - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.0.conv2.weight - Size: torch.Size([128, 128, 3, 3]) - Number of elements: 147456\n",
            "layer2.0.bn2.weight - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.0.bn2.bias - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.0.downsample.0.weight - Size: torch.Size([128, 64, 1, 1]) - Number of elements: 8192\n",
            "layer2.0.downsample.1.weight - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.0.downsample.1.bias - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.1.conv1.weight - Size: torch.Size([128, 128, 3, 3]) - Number of elements: 147456\n",
            "layer2.1.bn1.weight - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.1.bn1.bias - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.1.conv2.weight - Size: torch.Size([128, 128, 3, 3]) - Number of elements: 147456\n",
            "layer2.1.bn2.weight - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer2.1.bn2.bias - Size: torch.Size([128]) - Number of elements: 128\n",
            "layer3.0.conv1.weight - Size: torch.Size([256, 128, 3, 3]) - Number of elements: 294912\n",
            "layer3.0.bn1.weight - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.0.bn1.bias - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.0.conv2.weight - Size: torch.Size([256, 256, 3, 3]) - Number of elements: 589824\n",
            "layer3.0.bn2.weight - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.0.bn2.bias - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.0.downsample.0.weight - Size: torch.Size([256, 128, 1, 1]) - Number of elements: 32768\n",
            "layer3.0.downsample.1.weight - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.0.downsample.1.bias - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.1.conv1.weight - Size: torch.Size([256, 256, 3, 3]) - Number of elements: 589824\n",
            "layer3.1.bn1.weight - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.1.bn1.bias - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.1.conv2.weight - Size: torch.Size([256, 256, 3, 3]) - Number of elements: 589824\n",
            "layer3.1.bn2.weight - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer3.1.bn2.bias - Size: torch.Size([256]) - Number of elements: 256\n",
            "layer4.0.conv1.weight - Size: torch.Size([512, 256, 3, 3]) - Number of elements: 1179648\n",
            "layer4.0.bn1.weight - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.0.bn1.bias - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.0.conv2.weight - Size: torch.Size([512, 512, 3, 3]) - Number of elements: 2359296\n",
            "layer4.0.bn2.weight - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.0.bn2.bias - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.0.downsample.0.weight - Size: torch.Size([512, 256, 1, 1]) - Number of elements: 131072\n",
            "layer4.0.downsample.1.weight - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.0.downsample.1.bias - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.1.conv1.weight - Size: torch.Size([512, 512, 3, 3]) - Number of elements: 2359296\n",
            "layer4.1.bn1.weight - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.1.bn1.bias - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.1.conv2.weight - Size: torch.Size([512, 512, 3, 3]) - Number of elements: 2359296\n",
            "layer4.1.bn2.weight - Size: torch.Size([512]) - Number of elements: 512\n",
            "layer4.1.bn2.bias - Size: torch.Size([512]) - Number of elements: 512\n",
            "fc.weight - Size: torch.Size([10, 512]) - Number of elements: 5120\n",
            "fc.bias - Size: torch.Size([10]) - Number of elements: 10\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name} - Size: {param.size()} - Number of elements: {param.numel()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Biwb-ebya6TH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3038de3b-5828-4983-888c-63958a537b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 11181642\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5JEUocY4bDmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ebfb8d-707c-43e9-df66-0841b0a7566c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 11,181,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 106.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(3, 224, 224))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}