{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1UXBZ2kzoX1",
        "outputId": "1bfdb02b-9464-47a3-87bd-567d7f08ff75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR74754xWIR3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity, tensorboard_trace_handler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pynvml import *\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.cuda.current_device()  # 현재 GPU 디바이스 정보\n",
        "        allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # 메모리 사용량 (GB)\n",
        "        reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # 예약된 메모리 (GB)\n",
        "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
        "        print(f\"Reserved Memory: {reserved_memory:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No GPU available.\")"
      ],
      "metadata": {
        "id": "KutboPCzza4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ],
      "metadata": {
        "id": "_8xbvf80zvjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntBtU40OWIR5"
      },
      "outputs": [],
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkTBa1iCWIR5"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size, scale=(0.5, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68SaArxkWIR5",
        "outputId": "e210b543-291d-4c71-dcd0-f6b2bfc412c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HISYmEIlWIR6"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.7\n",
        "n_train_examples = int(len(trainset) * VALID_RATIO)\n",
        "n_valid_examples = len(trainset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(trainset, [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKkwwymDWIR6"
      },
      "outputs": [],
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kZE0KyvWIR6",
        "outputId": "5033c724-7feb-4754-b176-39da5621970e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 15000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_data), len(valid_data), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgFbnxO2WIR7"
      },
      "outputs": [],
      "source": [
        "sample_fraction = 0.2\n",
        "\n",
        "# 무작위 인덱스 생성\n",
        "train_indices = torch.randperm(len(trainset))[:int(len(trainset) * sample_fraction)]\n",
        "valid_indices = torch.randperm(len(valid_data))[:int(len(valid_data) * sample_fraction)]\n",
        "test_indices = torch.randperm(len(testset))[:int(len(testset) * sample_fraction)]\n",
        "\n",
        "# 서브셋 생성\n",
        "train_subset = Subset(trainset, train_indices)\n",
        "valid_subset = Subset(valid_data, valid_indices)\n",
        "test_subset = Subset(testset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UMCcWRjWIR7",
        "outputId": "371120b6-4391-4bfd-c61a-2afe992f340a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_subset), len(valid_subset), len(test_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIuqCxeGWIR7"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "valid_iterator = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)\n",
        "test_iterator = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mVcfuK7WIR7"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample = False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ijsu-aH8WIR7"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual = False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "                #elif isinstance(m, Bottleneck):\n",
        "                    #nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ2g6Vv5WIR8"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyqkNDbOWIR8"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock, n_blocks = [2, 2, 2, 2], channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvxhhdRPWIR8",
        "outputId": "e1ce965e-9144-47c9-de51-16cd7b6d6f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n"
          ]
        }
      ],
      "source": [
        "pretrained_model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApjRni8tWIR8",
        "outputId": "8d38ad25-b8c7-444e-f844-b2fd97a928fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGaz_A9yWIR8"
      },
      "outputs": [],
      "source": [
        "model = ResNet(resnet18_config, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf05XuEVY50-",
        "outputId": "397084f3-2148-48b8-b69c-c26ef7f7aaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fCSieg3WIR8"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pretrained_model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwVmEYKxWIR8"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElRmHAmtWIR8"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "        # 훈련 루프\n",
        "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # 기울기 초기화\n",
        "        outputs = model(inputs)  # 모델 연산\n",
        "        loss = criterion(outputs[0], labels)  # 손실 계산\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 파라미터 업데이트\n",
        "\n",
        "        running_loss += loss.item()  # 손실 누적\n",
        "        _, predicted = torch.max(outputs[0], 1)  # 예측 결과\n",
        "        total += labels.size(0)  # 총 데이터 수\n",
        "        correct += (predicted == labels).sum().item()  # 정확도 계산\n",
        "\n",
        "    # 훈련 후 평균 손실과 정확도 계산\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    #print(f\"Epoch: Loss = {epoch_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
        "\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcKNWVMyWIR8"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs[0], labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    # print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X3CMJVlWIR9"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CBXgAgVO0G4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiV3uFx69SM0",
        "outputId": "adb059e0-e7b9-47f5-d836-ea03f32c63ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated Memory: 0.04 GB\n",
            "Reserved Memory: 0.06 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX8BoA2oYyEc",
        "outputId": "8adfeda1-d67c-4a9f-8bfa-9984fe15c82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 40026.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsG0saouWIR9",
        "outputId": "ebc470ef-d47e-4bf1-cc18-ca3807b6dc5b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:23<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Train Time: 0m 23s\n",
            "\tTrain Loss: 2.028 | Train Acc: 25.77%\n",
            "\t Val. Loss: 1.821 |  Val. Acc: 33.77%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:20<00:00, 15.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Epoch Train Time: 0m 20s\n",
            "\tTrain Loss: 1.801 | Train Acc: 33.92%\n",
            "\t Val. Loss: 1.749 |  Val. Acc: 36.13%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:20<00:00, 15.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Epoch Train Time: 0m 20s\n",
            "\tTrain Loss: 1.709 | Train Acc: 37.93%\n",
            "\t Val. Loss: 1.609 |  Val. Acc: 41.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 15.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.620 | Train Acc: 40.58%\n",
            "\t Val. Loss: 1.530 |  Val. Acc: 42.33%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 16.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 19.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.562 | Train Acc: 43.87%\n",
            "\t Val. Loss: 1.480 |  Val. Acc: 46.20%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 15.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.517 | Train Acc: 45.29%\n",
            "\t Val. Loss: 1.584 |  Val. Acc: 42.60%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 16.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.457 | Train Acc: 47.10%\n",
            "\t Val. Loss: 1.398 |  Val. Acc: 49.27%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 16.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.424 | Train Acc: 48.13%\n",
            "\t Val. Loss: 1.349 |  Val. Acc: 50.83%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 16.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 21.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.389 | Train Acc: 49.54%\n",
            "\t Val. Loss: 1.280 |  Val. Acc: 54.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 313/313 [00:19<00:00, 16.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n",
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 94/94 [00:04<00:00, 20.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | Epoch Train Time: 0m 19s\n",
            "\tTrain Loss: 1.348 | Train Acc: 51.21%\n",
            "\t Val. Loss: 1.300 |  Val. Acc: 53.37%\n",
            "Train finished\n",
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "total_time = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, criterion, optimizer, device)\n",
        "    print_gpu_utilization()\n",
        "    free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "    print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "    print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")\n",
        "    end_time = time.monotonic()\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "    #if valid_loss < best_valid_loss:\n",
        "        #best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'vgg19-model.pt')\n",
        "\n",
        "    # end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    total_time += end_time - start_time\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Train Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
        "\n",
        "print(\"Train finished\")\n",
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_RbzQQEX9J5",
        "outputId": "7e40740f-50bf-4d73-8aa9-a9922afee0e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated Memory: 0.10 GB\n",
            "Reserved Memory: 1.40 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {free_memory / 1024**2:.2f} MB\")\n",
        "print(f\"Total memory: {total_memory / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mddh-LmVYhVe",
        "outputId": "1b565a09-e40c-4621-b35d-965c3eed8d7a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free memory: 38556.81 MB\n",
            "Total memory: 40513.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0YfjvTjYWIR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92303caf-ea10-4aa0-b857-39912f30f7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18 with dropout\n",
            "Total Training Time: 3m 20s\n"
          ]
        }
      ],
      "source": [
        "print(\"ResNet18 with dropout\")\n",
        "print(f'Total Training Time: {int(total_time/60)}m {int(total_time%60)}s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G2lgTlpwF2z",
        "outputId": "31c4b283-e463-4824-8d39-ec91c33c07a8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::conv2d         1.70%     100.022us        49.15%       2.888ms     144.407us       0.000us         0.00%       2.692ms     134.579us            20  \n",
            "                                      aten::convolution         2.38%     139.720us        47.45%       2.788ms     139.406us       0.000us         0.00%       2.692ms     134.579us            20  \n",
            "                                     aten::_convolution         2.67%     156.828us        45.07%       2.648ms     132.420us       0.000us         0.00%       2.692ms     134.579us            20  \n",
            "                                aten::cudnn_convolution        30.61%       1.799ms        42.40%       2.492ms     124.579us       2.692ms        65.37%       2.692ms     134.579us            20  \n",
            "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     658.176us        15.99%     658.176us      65.818us            10  \n",
            "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     651.230us        15.82%     651.230us      17.138us            38  \n",
            "                                       aten::batch_norm         1.20%      70.280us        29.95%       1.760ms      88.002us       0.000us         0.00%     641.661us      32.083us            20  \n",
            "                           aten::_batch_norm_impl_index         1.69%      99.174us        28.76%       1.690ms      84.488us       0.000us         0.00%     641.661us      32.083us            20  \n",
            "                                 aten::cudnn_batch_norm        11.86%     696.662us        27.07%       1.591ms      79.529us     641.661us        15.58%     641.661us      32.083us            20  \n",
            "void cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float,...         0.00%       0.000us         0.00%       0.000us       0.000us     641.661us        15.58%     641.661us      32.083us            20  \n",
            "sm80_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     485.727us        11.80%     485.727us     121.432us             4  \n",
            "                                            aten::relu_         1.88%     110.484us         8.79%     516.497us      30.382us       0.000us         0.00%     364.449us      21.438us            17  \n",
            "                                       aten::clamp_min_         4.33%     254.622us         6.91%     406.013us      23.883us     364.449us         8.85%     364.449us      21.438us            17  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     364.449us         8.85%     364.449us      21.438us            17  \n",
            "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     352.127us         8.55%     352.127us     352.127us             1  \n",
            "void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s168...         0.00%       0.000us         0.00%       0.000us       0.000us     261.567us         6.35%     261.567us      87.189us             3  \n",
            "                                       aten::max_pool2d         0.14%       8.142us         2.11%     124.145us     124.145us       0.000us         0.00%     207.647us     207.647us             1  \n",
            "                          aten::max_pool2d_with_indices         1.73%     101.883us         1.97%     116.003us     116.003us     207.647us         5.04%     207.647us     207.647us             1  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us     207.647us         5.04%     207.647us     207.647us             1  \n",
            "                                             aten::add_         2.40%     141.179us         3.50%     205.544us      25.693us     187.520us         4.55%     187.520us      23.440us             8  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     187.520us         4.55%     187.520us      23.440us             8  \n",
            "void cudnn::engines_precompiled::nhwcToNchwKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     175.457us         4.26%     175.457us      35.091us             5  \n",
            "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us      53.952us         1.31%      53.952us      53.952us             1  \n",
            "       _5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us      50.112us         1.22%      50.112us      50.112us             1  \n",
            "                              aten::adaptive_avg_pool2d         0.34%      19.938us         1.42%      83.159us      83.159us       0.000us         0.00%      12.352us      12.352us             1  \n",
            "                                             aten::mean         0.84%      49.294us         1.08%      63.221us      63.221us      12.352us         0.30%      12.352us      12.352us             1  \n",
            "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.352us         0.30%      12.352us      12.352us             1  \n",
            "                                           aten::linear         0.25%      14.641us         4.12%     242.317us     242.317us       0.000us         0.00%      12.192us      12.192us             1  \n",
            "                                            aten::addmm         2.81%     164.831us         3.18%     187.000us     187.000us      12.192us         0.30%      12.192us      12.192us             1  \n",
            "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       7.872us         0.19%       7.872us       7.872us             1  \n",
            "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us       4.320us         0.10%       4.320us       4.320us             1  \n",
            "void cask__5x_cudnn::computeOffsetsKernel<false, fal...         0.00%       0.000us         0.00%       0.000us       0.000us       3.232us         0.08%       3.232us       3.232us             1  \n",
            "                                        cudaEventRecord         1.57%      92.445us         1.57%      92.445us       2.311us       0.000us         0.00%       0.000us       0.000us            40  \n",
            "                                  cudaStreamIsCapturing         0.49%      28.619us         0.49%      28.619us       0.715us       0.000us         0.00%       0.000us       0.000us            40  \n",
            "                                  cudaStreamGetPriority         0.46%      27.154us         0.46%      27.154us       0.679us       0.000us         0.00%       0.000us       0.000us            40  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.40%      23.526us         0.40%      23.526us       0.588us       0.000us         0.00%       0.000us       0.000us            40  \n",
            "                                       cudaLaunchKernel        15.65%     919.541us        15.65%     919.541us       9.480us       0.000us         0.00%       0.000us       0.000us            97  \n",
            "                                    cudaPeekAtLastError         0.13%       7.915us         0.13%       7.915us       0.198us       0.000us         0.00%       0.000us       0.000us            40  \n",
            "                                    cudaLaunchKernelExC         1.84%     108.094us         1.84%     108.094us       6.756us       0.000us         0.00%       0.000us       0.000us            16  \n",
            "                                       aten::empty_like         1.80%     105.554us         5.17%     303.557us      15.178us       0.000us         0.00%       0.000us       0.000us            20  \n",
            "                                            aten::empty         7.53%     442.562us         7.53%     442.562us       5.532us       0.000us         0.00%       0.000us       0.000us            80  \n",
            "                                             aten::view         1.38%      81.177us         1.38%      81.177us       3.866us       0.000us         0.00%       0.000us       0.000us            21  \n",
            "                                   cudaFuncSetAttribute         0.63%      36.969us         0.63%      36.969us       1.120us       0.000us         0.00%       0.000us       0.000us            33  \n",
            "                                        cudaMemsetAsync         0.01%       0.508us         0.01%       0.508us       0.508us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                                aten::t         0.23%      13.259us         0.69%      40.676us      40.676us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                        aten::transpose         0.21%      12.194us         0.47%      27.417us      27.417us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                       aten::as_strided         0.26%      15.223us         0.26%      15.223us      15.223us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                  cudaDeviceSynchronize         0.59%      34.742us         0.59%      34.742us      34.742us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.876ms\n",
            "Self CUDA time total: 4.117ms\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}